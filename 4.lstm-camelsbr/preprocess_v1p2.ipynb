{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fdbfbf-6fe9-4df7-8b0f-fdeeb98d6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "import pandas as pd\n",
    "import xarray\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c34f3be2-9166-493e-934e-e2d2c1a8ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_camels_br_dataset(data_dir: Path):\n",
    "    \"\"\"Preprocess CAMELS-BR data set and create per-basin files for more flexible and faster data loading.\n",
    "    \n",
    "    This function will read-in all time series text files and create per-basin csv files containing all timeseries \n",
    "    features at once in a new subfolder called \"preprocessed\". Will only consider the 897 basin for which streamflow and\n",
    "    forcings exist. Note that simulated streamflow only exists for 593 out of 897 basins.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir : Path\n",
    "        Path to the CAMELS-BR data set containing the different subdirectories that can be downloaded as individual zip\n",
    "        archives.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    FileExistsError\n",
    "        If a sub-folder called 'preprocessed' already exists in `data_dir`.\n",
    "    FileNotFoundError\n",
    "        If any of the subdirectories of CAMELS-BR is not found in `data_dir`, specifically the folders starting with \n",
    "        `03_*` up to `13_*`.\n",
    "    \"\"\"\n",
    "    # check if data has already been pre-processed other-wise create dst folder\n",
    "    dst_dir = data_dir / \"preprocessed\"\n",
    "   # if dst_dir.is_dir():\n",
    "   #     raise FileExistsError(\n",
    "   #         \"Subdirectory 'preprocessed' already exists. Delete this folder if you want to reprocess the data.\")\n",
    "   # dst_dir.mkdir()\n",
    "\n",
    "    # Streamflow and forcing data are stored in different subdirectories that start with a numeric value each. The first\n",
    "    # one is streamflow mm/d starting with 03 and the last is max temp starting with 13.\n",
    "    timeseries_folders = [data_dir / subdirectory for subdirectory in _CAMELS_BR_TIMESERIES_SUBDIRS]\n",
    "    if any([not p.is_dir() for p in timeseries_folders]):\n",
    "        missing_subdirectories = [p.name for p in timeseries_folders if not p.is_dir()]\n",
    "        raise FileNotFoundError(\n",
    "            f\"The following directories were expected in {data_dir} but do not exist: {missing_subdirectories}\")\n",
    "\n",
    "    # Since files is sorted, we can pick the first one, streamflow, and extract the basins names from there\n",
    "    basins = [x.stem.split('_')[0] for x in timeseries_folders[0].glob('*.txt')]\n",
    "    print(f\"Found {len(basins)} basin files under {timeseries_folders[0].name}\")\n",
    "\n",
    "    for basin in tqdm(basins, desc=\"Combining timeseries data from different subdirectories into one file per basin\"):\n",
    "        data = {}\n",
    "        for timeseries_folder in timeseries_folders:\n",
    "            basin_file = list(timeseries_folder.glob(f'{basin}_*'))\n",
    "            if basin_file:\n",
    "                df = pd.read_csv(basin_file[0], sep=' ')\n",
    "                df[\"date\"] = pd.to_datetime(df.year.map(str) + \"/\" + df.month.map(str) + \"/\" + df.day.map(str),\n",
    "                                            format=\"%Y/%m/%d\")\n",
    "                df = df.set_index('date')\n",
    "                feat_cols = [c for c in df.columns if c not in ['year', 'month', 'day']]\n",
    "                for col in feat_cols:\n",
    "                    data[col] = df[col]\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(dst_dir / f\"{basin}.csv\")\n",
    "\n",
    "    print(f\"Finished processing the CAMELS-BR data set. Resulting per-basin csv files have been stored at {dst_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3793bc77-cf84-4406-84fd-b0eb23256ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_CAMELS_BR_TIMESERIES_SUBDIRS = [\n",
    "    '03_CAMELS_BR_streamflow_selected_catchments',\n",
    "#    '04_CAMELS_BR_streamflow_simulated',\n",
    "    '05_CAMELS_BR_precipitation',\n",
    "    '06_CAMELS_BR_actual_evapotransp',\n",
    "    '07_CAMELS_BR_potential_evapotransp',\n",
    "    '08_CAMELS_BR_reference_evapotransp',\n",
    "    '09_CAMELS_BR_temperature',\n",
    "    '10_CAMELS_BR_soil_moisture',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "012e120b-c5a4-4cb1-8276-173d9e76fb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 897 basin files under 03_CAMELS_BR_streamflow_selected_catchments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining timeseries data from different subdirectories into one file per basin: 100%|██████████| 897/897 [14:17<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing the CAMELS-BR data set. Resulting per-basin csv files have been stored at ../../DATA/1.Spatial_data/global/sw_surfacewater_streamflow_runoff_river_network_waterstress/camels-br/preprocessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocess_camels_br_dataset(Path(\"../../DATA/1.Spatial_data/global/sw_surfacewater_streamflow_runoff_river_network_waterstress/camels-br/\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
